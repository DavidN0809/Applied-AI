Name: David Nichols
Date: 9/19/2024

1. Introduction
This assignment focuses on building a convolutional neural network (CNN) classifier to distinguish between images of cats and dogs using transfer learning. Pre-trained models such as VGG16 are used, along with custom data loaders and data augmentation techniques. This document outlines the process, including data preprocessing, model training, fine-tuning, and evaluation.

2. Dataset and Preprocessing
Step 1: Dataset Download and Split
The dataset used consists of 25,000 images of cats and dogs. It was downloaded from Kaggle, extracted, and split into a training and validation set.

Training Set: 80% of the data.
Validation Set: 20% of the data.
The dataset is shuffled and split using the train_test_split function from sklearn.

# Shuffle and split dataset
df_train, df_valid = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)
To improve the model's ability to generalize, data augmentation techniques were applied using the ImageDataGenerator from Keras. The following augmentations were applied:

Rotation: Random rotations.
Flipping: Horizontal and vertical flips.
Zooming: Random zooming.
Rescaling: All pixel values are normalized.
# Preview the augmented data
X_preview, y_preview = train_generator.next()
for k in range(1, 7):
    sample_img = X_preview[k, :, :, :]
    plt.subplot(2, 3, k)
    plt.imshow(sample_img)

3. Model Building Using Transfer Learning
Step 3: Pre-trained Model (VGG16)
Transfer learning was employed using the VGG16 architecture pre-trained on the ImageNet dataset. The last few layers of VGG16 were modified to include custom fully connected (dense) layers for the binary classification of dogs and cats.

Base Model: VGG16 (pre-trained).
Custom Layers: Dense layers with ReLU activation and dropout for regularization.
# Model summary
model.summary()


Here’s a structured approach to writing the word document for your assignment. You can copy this format into a Word document and fill in the necessary screenshots, code snippets, and explanations as needed.

Title: Dog/Cat Classifier using Transfer Learning
Name: David Nichols
Email: david.nichols.cpe@gmail.com
Date: [Today's Date]

1. Introduction
This assignment focuses on building a convolutional neural network (CNN) classifier to distinguish between images of cats and dogs using transfer learning. Pre-trained models such as VGG16 are used, along with custom data loaders and data augmentation techniques. This document outlines the process, including data preprocessing, model training, fine-tuning, and evaluation.

2. Dataset and Preprocessing
Step 1: Dataset Download and Split
The dataset used consists of 25,000 images of cats and dogs. It was downloaded from Kaggle, extracted, and split into a training and validation set.

Training Set: 80% of the data.
Validation Set: 20% of the data.
The dataset is shuffled and split using the train_test_split function from sklearn.

Screenshot: Show the code for splitting the dataset.

python
Copy code
# Shuffle and split dataset
df_train, df_valid = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)
Step 2: Data Preprocessing and Augmentation
To improve the model's ability to generalize, data augmentation techniques were applied using the ImageDataGenerator from Keras. The following augmentations were applied:

Rotation: Random rotations.
Flipping: Horizontal and vertical flips.
Zooming: Random zooming.
Rescaling: All pixel values are normalized.
Screenshot: Display augmented sample images using plt.imshow().

python
Copy code
# Preview the augmented data
X_preview, y_preview = train_generator.next()
for k in range(1, 7):
    sample_img = X_preview[k, :, :, :]
    plt.subplot(2, 3, k)
    plt.imshow(sample_img)
3. Model Building Using Transfer Learning
Step 3: Pre-trained Model (VGG16)
Transfer learning was employed using the VGG16 architecture pre-trained on the ImageNet dataset. The last few layers of VGG16 were modified to include custom fully connected (dense) layers for the binary classification of dogs and cats.

Base Model: VGG16 (pre-trained).
Custom Layers: Dense layers with ReLU activation and dropout for regularization.
Screenshot: Display the architecture summary of the model (model.summary()).

python
Copy code
# Model summary
model.summary()
Step 4: Fine-Tuning the Model
Fine-tuning was done by unfreezing the last layers of the VGG16 model and retraining it on the cat/dog dataset. This allows the model to adjust its pre-trained weights for this specific task.

Learning Rate: Set to 0.001 initially, with a learning rate scheduler to reduce it if the model stops improving.
Optimization: Adam optimizer was used.
Loss Function: Binary cross-entropy for two classes (dogs and cats).
# Learning rate scheduler
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)

4. Custom Data Loader
Step 5: Custom ImageLoader
A custom data loader (ImageLoader) was written to manually load, preprocess, and augment the images without using the ImageDataGenerator. The loader applies the following augmentations:

Rotation: Random rotations.
Zoom: Random zooming.
Brightness Adjustment: Random brightness changes.
# Sample augmentation visualization
X_preview, y_preview = train_loader.__getitem__(0)
for k in range(1, 7):
    sample_img = X_preview[k, :, :, :]
    plt.subplot(2, 3, k)
    plt.imshow(sample_img)
5. Training, Evaluation, and Visualization
Step 6: Model Training
The model was trained for 100 epochs with early stopping to prevent overfitting. The training process was tracked using TensorBoard for real-time visualization of loss and accuracy.

Epochs: 100.
Early Stopping: To stop the training when the validation loss no longer improves.
Model Checkpoint: To save the best-performing model during training.

# Plot Training & Validation Accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')


Here’s a structured approach to writing the word document for your assignment. You can copy this format into a Word document and fill in the necessary screenshots, code snippets, and explanations as needed.

Title: Dog/Cat Classifier using Transfer Learning
Name: David Nichols
Email: david.nichols.cpe@gmail.com
Date: [Today's Date]

1. Introduction
This assignment focuses on building a convolutional neural network (CNN) classifier to distinguish between images of cats and dogs using transfer learning. Pre-trained models such as VGG16 are used, along with custom data loaders and data augmentation techniques. This document outlines the process, including data preprocessing, model training, fine-tuning, and evaluation.

2. Dataset and Preprocessing
Step 1: Dataset Download and Split
The dataset used consists of 25,000 images of cats and dogs. It was downloaded from Kaggle, extracted, and split into a training and validation set.

Training Set: 80% of the data.
Validation Set: 20% of the data.
The dataset is shuffled and split using the train_test_split function from sklearn.

Screenshot: Show the code for splitting the dataset.

python
Copy code
# Shuffle and split dataset
df_train, df_valid = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)
Step 2: Data Preprocessing and Augmentation
To improve the model's ability to generalize, data augmentation techniques were applied using the ImageDataGenerator from Keras. The following augmentations were applied:

Rotation: Random rotations.
Flipping: Horizontal and vertical flips.
Zooming: Random zooming.
Rescaling: All pixel values are normalized.
Screenshot: Display augmented sample images using plt.imshow().

python
Copy code
# Preview the augmented data
X_preview, y_preview = train_generator.next()
for k in range(1, 7):
    sample_img = X_preview[k, :, :, :]
    plt.subplot(2, 3, k)
    plt.imshow(sample_img)
3. Model Building Using Transfer Learning
Step 3: Pre-trained Model (VGG16)
Transfer learning was employed using the VGG16 architecture pre-trained on the ImageNet dataset. The last few layers of VGG16 were modified to include custom fully connected (dense) layers for the binary classification of dogs and cats.

Base Model: VGG16 (pre-trained).
Custom Layers: Dense layers with ReLU activation and dropout for regularization.
Screenshot: Display the architecture summary of the model (model.summary()).

python
Copy code
# Model summary
model.summary()
Step 4: Fine-Tuning the Model
Fine-tuning was done by unfreezing the last layers of the VGG16 model and retraining it on the cat/dog dataset. This allows the model to adjust its pre-trained weights for this specific task.

Learning Rate: Set to 0.001 initially, with a learning rate scheduler to reduce it if the model stops improving.
Optimization: Adam optimizer was used.
Loss Function: Binary cross-entropy for two classes (dogs and cats).
Screenshot: Display the learning rate scheduler code and explanation.

python
Copy code
# Learning rate scheduler
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)
4. Custom Data Loader
Step 5: Custom ImageLoader
A custom data loader (ImageLoader) was written to manually load, preprocess, and augment the images without using the ImageDataGenerator. The loader applies the following augmentations:

Rotation: Random rotations.
Zoom: Random zooming.
Brightness Adjustment: Random brightness changes.
Screenshot: Display the ImageLoader class code and example output of the loaded and augmented images.

python
Copy code
# Sample augmentation visualization
X_preview, y_preview = train_loader.__getitem__(0)
for k in range(1, 7):
    sample_img = X_preview[k, :, :, :]
    plt.subplot(2, 3, k)
    plt.imshow(sample_img)
5. Training, Evaluation, and Visualization
Step 6: Model Training
The model was trained for 100 epochs with early stopping to prevent overfitting. The training process was tracked using TensorBoard for real-time visualization of loss and accuracy.

Epochs: 100.
Early Stopping: To stop the training when the validation loss no longer improves.
Model Checkpoint: To save the best-performing model during training.
Screenshot: Show training/validation accuracy and loss plots.

python
Copy code
# Plot Training & Validation Accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
Step 7: Evaluation (Confusion Matrix)
The model's performance was evaluated using a confusion matrix to assess how well it distinguished between dogs and cats.

Screenshot: Display the confusion matrix.

python
Copy code
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=valid_generator.class_indices)
disp.plot(cmap=plt.cm.Blues)

6. Conclusion
The transfer learning approach using VGG16 provided satisfactory results in classifying cats and dogs. Fine-tuning the model improved its accuracy, and using custom data loaders allowed us to apply various augmentations manually.

TensorBoard was a valuable tool for tracking the model’s performance over time, and the final model achieved good accuracy on the validation set, as seen in the confusion matrix and loss/accuracy plots.
